{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unsupervised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erikrozi/acmlab/blob/main/unsupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2MLzIllFeoH",
        "outputId": "cb54d74b-730a-48db-88d2-e3dd383ef29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# this mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in the Shared Google Drive\n",
        "FOLDERNAME = 'Shared drives/Unsupervised'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/$FOLDERNAME/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shared drives/Unsupervised\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUGAIt31FkZH"
      },
      "source": [
        "# Importing the standard ML libraries...\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import pandas as pd                     # to process our data\n",
        "import matplotlib.pyplot as plt         # graphing\n",
        "import numpy as np                      # matrices\n",
        "\n",
        "import torch\n",
        "import torchvision                      # for MNIST dataset/working with images\n",
        "\n",
        "import math\n",
        "\n",
        "# take advantage of GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80ZcQGejHjWq"
      },
      "source": [
        "# Load Census Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGws6kpXsp4-"
      },
      "source": [
        "# Loads data with zip and aveincome\n",
        "tax_returns_data = pd.read_csv(\"16zpallnoagi.csv\")\n",
        "cleaned_tax_data = pd.DataFrame(tax_returns_data, columns = [\"ZIPCODE\", \"N1\", \"A02650\"])\n",
        "cleaned_tax_data = cleaned_tax_data[(cleaned_tax_data['ZIPCODE'] <= 97000) & (cleaned_tax_data['ZIPCODE'] >= 90000)] #remove zipcodes not in california\n",
        "cleaned_tax_data.columns = ['zip', 'N1', 'A02650']\n",
        "cleaned_tax_data['aveincome'] = ((cleaned_tax_data['A02650'] / cleaned_tax_data['N1']) * 1000).astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkDndKuAvAir"
      },
      "source": [
        "# Loads zips for Los Angeles\n",
        "ziplation_data = pd.read_csv(\"ziplatlon.csv\", sep = \";\")\n",
        "parsed_ziplation_data = ziplation_data[(ziplation_data['latitude'] <= 34.3) & (ziplation_data['latitude'] >= 33.5) & (ziplation_data['longitude'] >= -118.6) & (ziplation_data['longitude'] <= -117.6)]\n",
        "parsed_ziplation_data = pd.merge(parsed_ziplation_data, cleaned_tax_data, how='left', on= 'zip')\n",
        "parsed_ziplation_data = parsed_ziplation_data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCBVBumNzrOg"
      },
      "source": [
        "import util as util\n",
        "import webmercator as webmercator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8tKLryEsTtY"
      },
      "source": [
        "# creates image data and pulls latitude and longitude\n",
        "z = 14\n",
        "pos = np.empty([1980, 5])\n",
        "for x in range(2794, 2839):\n",
        "  for y in range(6528, 6572):\n",
        "    curPos = (x - 2794) * (6572 - 6528) + (y - 6528)\n",
        "    pos[curPos, 0] = x\n",
        "    pos[curPos, 1] = y\n",
        "    pos[curPos, 2] = webmercator.lat(y, z)\n",
        "    pos[curPos, 3] = webmercator.lon(x, z)\n",
        "    pos[curPos, 4] = util.getElevation(pos[curPos, 2], pos[curPos, 3])\n",
        "image_pos_data = pd.DataFrame({'x': pos[:,0].astype(int), 'y': pos[:,1].astype(int), 'z': 14, 'latitude': pos[:,2], 'longitude': pos[:,3], 'elevation': pos[:,4]})\n",
        "image_pos_data['img'] = \"14_\" + image_pos_data['x'].astype(str) + \"_\" + image_pos_data['y'].astype(str) + \".jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eAnrRNQ7g2c"
      },
      "source": [
        "Maps image to closest zip code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDlF4ymD7gZP"
      },
      "source": [
        "def calc_distance(lat1, long1, lat2, long2):\n",
        "  xdist = long1 - long2\n",
        "  ydist = lat1 - lat2\n",
        "  return math.sqrt(xdist**2 + ydist**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om5khrG0IeU6"
      },
      "source": [
        "np_ziplation = parsed_ziplation_data.to_numpy()\n",
        "tile_zips = np.empty([image_pos_data.shape[0], 1])\n",
        "\n",
        "np_ziplation.shape\n",
        "\n",
        "#very inefficient lol\n",
        "#for each image tile, loops through all the possible zipcodes, and chooses the one with the smallest distance\n",
        "for i in range(image_pos_data.shape[0]):\n",
        "  min_dist = 100000 #just made this an arbitrarily large number cuz iwas lazy\n",
        "  for j in range(np_ziplation.shape[0]):\n",
        "    zip_coords = np_ziplation[j][7].split(\",\") #splitting geopoint coords into latitude and longitude\n",
        "    pt = image_pos_data['latitude'][i]\n",
        "    cur_dist = calc_distance(pt, image_pos_data['longitude'][i], float(zip_coords[0]), float(zip_coords[1]))\n",
        "    if cur_dist < min_dist:\n",
        "      min_dist = cur_dist\n",
        "      tile_zips[i] = np_ziplation[j][0]\n",
        "image_pos_data['zipcode'] = tile_zips.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyaDnuBs4GUe"
      },
      "source": [
        "# Gets rid of ocean tiles\n",
        "image_pos_data = image_pos_data[~(image_pos_data['elevation'] == 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AXGWnAh3inM",
        "outputId": "c22dcb96-cab0-441b-bbae-f2afac8df8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "image_income_data = pd.DataFrame(image_pos_data, columns = ['img', 'zipcode'])\n",
        "image_income_data.columns = ['img', 'zip']\n",
        "image_income_data = pd.merge(image_income_data, cleaned_tax_data, how='left', on='zip')\n",
        "image_income_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>zip</th>\n",
              "      <th>N1</th>\n",
              "      <th>A02650</th>\n",
              "      <th>aveincome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14_2794_6528.jpg</td>\n",
              "      <td>91311</td>\n",
              "      <td>18560</td>\n",
              "      <td>1694366</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14_2794_6529.jpg</td>\n",
              "      <td>91311</td>\n",
              "      <td>18560</td>\n",
              "      <td>1694366</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14_2794_6530.jpg</td>\n",
              "      <td>91311</td>\n",
              "      <td>18560</td>\n",
              "      <td>1694366</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14_2794_6531.jpg</td>\n",
              "      <td>91311</td>\n",
              "      <td>18560</td>\n",
              "      <td>1694366</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14_2794_6532.jpg</td>\n",
              "      <td>91311</td>\n",
              "      <td>18560</td>\n",
              "      <td>1694366</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>14_2838_6567.jpg</td>\n",
              "      <td>92692</td>\n",
              "      <td>23430</td>\n",
              "      <td>2676168</td>\n",
              "      <td>114219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>14_2838_6568.jpg</td>\n",
              "      <td>92694</td>\n",
              "      <td>11460</td>\n",
              "      <td>2027274</td>\n",
              "      <td>176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>14_2838_6569.jpg</td>\n",
              "      <td>92694</td>\n",
              "      <td>11460</td>\n",
              "      <td>2027274</td>\n",
              "      <td>176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>14_2838_6570.jpg</td>\n",
              "      <td>92694</td>\n",
              "      <td>11460</td>\n",
              "      <td>2027274</td>\n",
              "      <td>176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>14_2838_6571.jpg</td>\n",
              "      <td>92675</td>\n",
              "      <td>16750</td>\n",
              "      <td>2172841</td>\n",
              "      <td>129721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1457 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   img    zip     N1   A02650  aveincome\n",
              "0     14_2794_6528.jpg  91311  18560  1694366      91291\n",
              "1     14_2794_6529.jpg  91311  18560  1694366      91291\n",
              "2     14_2794_6530.jpg  91311  18560  1694366      91291\n",
              "3     14_2794_6531.jpg  91311  18560  1694366      91291\n",
              "4     14_2794_6532.jpg  91311  18560  1694366      91291\n",
              "...                ...    ...    ...      ...        ...\n",
              "1452  14_2838_6567.jpg  92692  23430  2676168     114219\n",
              "1453  14_2838_6568.jpg  92694  11460  2027274     176900\n",
              "1454  14_2838_6569.jpg  92694  11460  2027274     176900\n",
              "1455  14_2838_6570.jpg  92694  11460  2027274     176900\n",
              "1456  14_2838_6571.jpg  92675  16750  2172841     129721\n",
              "\n",
              "[1457 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVTvPujE63cU",
        "outputId": "fae60595-9423-471f-96c5-960a6432a569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "image_income_data = image_income_data[['img', 'aveincome']]\n",
        "image_income_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>aveincome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14_2794_6528.jpg</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14_2794_6529.jpg</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14_2794_6530.jpg</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14_2794_6531.jpg</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14_2794_6532.jpg</td>\n",
              "      <td>91291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>14_2838_6567.jpg</td>\n",
              "      <td>114219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>14_2838_6568.jpg</td>\n",
              "      <td>176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>14_2838_6569.jpg</td>\n",
              "      <td>176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>14_2838_6570.jpg</td>\n",
              "      <td>176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>14_2838_6571.jpg</td>\n",
              "      <td>129721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1457 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   img  aveincome\n",
              "0     14_2794_6528.jpg      91291\n",
              "1     14_2794_6529.jpg      91291\n",
              "2     14_2794_6530.jpg      91291\n",
              "3     14_2794_6531.jpg      91291\n",
              "4     14_2794_6532.jpg      91291\n",
              "...                ...        ...\n",
              "1452  14_2838_6567.jpg     114219\n",
              "1453  14_2838_6568.jpg     176900\n",
              "1454  14_2838_6569.jpg     176900\n",
              "1455  14_2838_6570.jpg     176900\n",
              "1456  14_2838_6571.jpg     129721\n",
              "\n",
              "[1457 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LdMD5FvFn4I"
      },
      "source": [
        "# Load the imagery data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa73VArKFs9W"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class TileImageryDataset(Dataset):\n",
        "  \"\"\"Tile imagery dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, images_to_incomes, root_dir, transform=None):\n",
        "    # Load into tensors\n",
        "    self.annotations = images_to_incomes\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "    # Perform data augmentation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = os.path.join(self.root_dir. self.annotations.iloc[index,0])\n",
        "    image = io.imread(image_path)\n",
        "    y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return (image, y_label)\n",
        "\n",
        "  #def load_images():\n",
        "  #  tensors = []\n",
        "  #  for x in range(2794, 2839):\n",
        "  #    for y in range(6528, 6572):\n",
        "  #      image = Image.open(f\"images/14_{x}_{y}.jpg\").convert(\"RGB\")\n",
        "  #      # TODO change\n",
        "  #      #jaden\n",
        "  #      data = asarray(image) #convert to np array, could also do np.array(Image.open...)\n",
        "  #      data = torch.from_numpy(data) #convert to tensor\n",
        "  #      preprocess = transforms.Compose([\n",
        "  #          transforms.Resize(256),\n",
        "  #          transforms.CenterCrop(224),\n",
        "  #          transforms.ToTensor(),\n",
        "  #          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  #      ])\n",
        "  #      input_tensor = preprocess(image)\n",
        "  #      # tensory push thing?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N5Qe0Lfscet"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "batch_size = 10\n",
        "\n",
        "dataset = TileImageryDataset(images_to_incomes = image_income_data, root_dir = 'imagery/', transform = transforms.ToTensor())\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [1200, 257])\n",
        "\n",
        "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr0uTKe5Bsgb"
      },
      "source": [
        "figure = plt.figure(figsize=(15, 10))\n",
        "num_rows = 8\n",
        "num_cols = 8\n",
        "for idx in range(batch_size):\n",
        "  plt.subplot(num_rows, num_cols, idx + 1) # subplot indices begin at 1, not 0\n",
        "  plt.axis('off')\n",
        "  plt.imshow(images[idx].squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsHWh4e6sb9h"
      },
      "source": [
        ""
      ]
    }
  ]
}